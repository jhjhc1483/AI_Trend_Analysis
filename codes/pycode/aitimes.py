from selenium import webdriver
from selenium.webdriver.common.keys import Keys
import time
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.chrome.service import Service # Service í´ë˜ìŠ¤ ì„í¬íŠ¸
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
import requests
from bs4 import BeautifulSoup
import re
import pandas as pd
import os
import json


# --- Options ì„¤ì • ë¶€ë¶„ ìˆ˜ì • ---
chrome_options = webdriver.ChromeOptions()

# 1. Headless ëª¨ë“œ ì„¤ì • (GUI ì—†ì´ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹¤í–‰)
chrome_options.add_argument('--headless')

# 2. ìƒŒë“œë°•ìŠ¤ ë¹„í™œì„±í™” (GitHub Actions/Docker í™˜ê²½ì—ì„œ í•„ìˆ˜)
chrome_options.add_argument('--no-sandbox')

# 3. /dev/shm ì‚¬ìš© ë¹„í™œì„±í™” (ë¦¬ì†ŒìŠ¤ ì œí•œ í™˜ê²½ì—ì„œ ì¶©ëŒ ë°©ì§€)
chrome_options.add_argument('--disable-dev-shm-usage')

# 4. ê¸°íƒ€ ìœ ìš©í•œ ì˜µì…˜ë“¤
chrome_options.add_argument('--window-size=1920,1080')
chrome_options.add_argument('--disable-gpu') # GPU ì‚¬ìš© ë¹„í™œì„±í™”
# ------------------------------

# serviceì™€ optionsë¥¼ ì‚¬ìš©í•˜ì—¬ ë¸Œë¼ìš°ì € ì´ˆê¸°í™”
# ì˜ˆì‹œ: service = Service(ChromeDriverManager().install())
# browser = webdriver.Chrome(service=service, options=chrome_options)


# 1. ë“œë¼ì´ë²„ ì‹¤í–‰ íŒŒì¼ ê²½ë¡œ ì§€ì •
CHROME_DRIVER_PATH = 'C:/chromedriver.exe'

# 2. Service ê°ì²´ ìƒì„± ì‹œ ê²½ë¡œ ì „ë‹¬

service = Service(executable_path=ChromeDriverManager().install())
chrome_options = Options()
chrome_options.add_experimental_option("detach",True)

#ë¶ˆí•„ìš”í•œ ì—ëŸ¬ ë©”ì‹œì§€ ì—†ì• ê¸°
chrome_options.add_experimental_option("excludeSwitches",["enable=logging"])
# 3. Service ê°ì²´ë¥¼ ì‚¬ìš©í•˜ì—¬ WebDriver ì´ˆê¸°í™”
# ì´ì œ webdriver.Chrome()ì—ëŠ” Service ê°ì²´ë¥¼ keyword argumentë¡œ ì „ë‹¬í•©ë‹ˆë‹¤.
browser = webdriver.Chrome(service=service, options=chrome_options)

# ì›¹ì‚¬ì´íŠ¸ ì—´ê¸°
browser.get('https://www.aitimes.com/news/articleList.html?page=1&total=29543&sc_section_code=&sc_sub_section_code=&sc_serial_code=&sc_area=&sc_level=&sc_article_type=&sc_view_level=&sc_sdate=&sc_edate=&sc_serial_number=&sc_word=&sc_andor=&sc_word2=&box_idxno=&sc_multi_code=&sc_is_image=&sc_is_movie=&sc_user_name=&sc_order_by=E')
browser.implicitly_wait(10)

driver = None # ë“œë¼ì´ë²„ ê°ì²´ë¥¼ try/finally ì™¸ë¶€ì—ì„œ ì„ ì–¸
more_button = browser.find_element(By.CSS_SELECTOR, '.button.expanded.nd-white.list-btn-more')
# more_button.click()
# more_button.click()
# more_button.click()
# more_button.click()
#more_button.click()
#more_button.click()
#more_button.click()
#more_button.click()

items = browser.find_elements(By.CSS_SELECTOR, '.altlist-text-item')
data = []
for item in items:
    name=item.find_element(By.CSS_SELECTOR,'.altlist-subject').text
    link = str(item.find_element(By.CSS_SELECTOR,'.altlist-subject > a').get_attribute('href'))
    print(link)
    if link == "":
        break
    response = requests.get(link)
    html = response.text
    soup = BeautifulSoup(html, 'html.parser')   
    date = soup.select_one(".breadcrumbs > li:nth-child(2)").text.strip() 
    parts = date.split(' ')
    date_part = parts[1]  
    time_part = parts[2] 
    d = date_part.split('.')
    years = d[0]
    month = d[1]
    day = d[2]
    d1 = time_part.split(':')
    hour = d1[0]
    # print(hour)
    #minute_temp = d1[1].split('"\"')
    minute_with_extras = d1[1].strip()
    minute = re.sub(r'[^0-9]', '', minute_with_extras)
    # print(name)
    # print(minute)
    data.append([name,link,years,month,day,hour,minute])
    

df1 = pd.DataFrame(data, columns=['ê¸°ì‚¬ëª…','ë§í¬','ë…„','ì›”','ì¼','ì‹œ','ë¶„'])
df1['ê¸°ì‚¬ëª…'] = df1['ê¸°ì‚¬ëª…'].fillna('').str.replace(r'\\', '', regex=True)
df1['ê¸°ì‚¬ëª…'] = df1['ê¸°ì‚¬ëª…'].str.replace('\'', 'ï¼‡', regex=False)
df1['ê¸°ì‚¬ëª…'] = df1['ê¸°ì‚¬ëª…'].str.replace('\"', 'ã€ƒ', regex=False)



# =============================================================
# ì…€ 6: JSON íŒŒì¼ ì´ì–´ ë¶™ì´ê¸° ë° ì €ì¥ ë¡œì§ (ê²½ë¡œ ìˆ˜ì •ë¨)
# =============================================================

# ğŸ’¡ í˜„ì¬ ìŠ¤í¬ë¦½íŠ¸ì™€ ë™ì¼í•œ ë””ë ‰í† ë¦¬(code í´ë”)ì— ì €ì¥ë©ë‹ˆë‹¤.
full_path = 'codes/aitimes.json' 
new_data = df1.to_dict('records')

existing_data = []

# 1. ê¸°ì¡´ JSON íŒŒì¼ ë¡œë“œ
if os.path.exists(full_path):
    try:
        with open(full_path, 'r', encoding='utf-8') as f:
            content = f.read()
            if content:
                existing_data = json.loads(content)
            else:
                print("ê¸°ì¡´ JSON íŒŒì¼ì€ ì¡´ì¬í•˜ì§€ë§Œ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. ìƒˆ ë°ì´í„°ë§Œ ì €ì¥í•©ë‹ˆë‹¤.")
    except Exception as e:
        print(f"ê¸°ì¡´ JSON íŒŒì¼ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ ({e}). ìƒˆ ë°ì´í„°ë§Œ ì €ì¥í•©ë‹ˆë‹¤.")
        existing_data = []

# 2. ìƒˆ ë°ì´í„°ì™€ ê¸°ì¡´ ë°ì´í„°ë¥¼ í•©ì¹˜ê¸°
combined_data = existing_data + new_data

# 3. ì¤‘ë³µ ì œê±°
seen_links = set()
final_data = []

for item in combined_data:
    link = item.get('ë§í¬')
    if link and link not in seen_links:
        final_data.append(item)
        seen_links.add(link)
        
print(f"ì´ {len(existing_data)}ê°œì˜ ê¸°ì¡´ ë°ì´í„°ì™€ {len(new_data)}ê°œì˜ ìƒˆ ë°ì´í„°ë¥¼ í•©ì³¤ìŠµë‹ˆë‹¤.")
print(f"ì¤‘ë³µì„ ì œê±°í•œ í›„ ìµœì¢… ë°ì´í„°ëŠ” ì´ {len(final_data)}ê°œì…ë‹ˆë‹¤.")

# 4. ìµœì¢… ë°ì´í„°ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥
with open(full_path, 'w', encoding='utf-8') as f:
    json.dump(final_data, f, indent=4, ensure_ascii=False)

print(f"\nìµœì¢… ë°ì´í„°ê°€ '{full_path}'ì— ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

